%% =====================================================================
%% A. Foundational Concepts & General Reviews
%% =====================================================================
%% This section includes broad review papers that provide a comprehensive overview of the V2G landscape,
%% the role of AI, and the integration challenges with the smart grid.

  %% A key review paper summarizing the state-of-the-art of Reinforcement Learning applications for V2G,
  %% providing a strong foundation for the literature review chapter.
@article{alsabbagh2022reinforcement,

  title={Reinforcement learning for vehicle-to-grid: a review},
  author={Alsabbagh, Mohamad and Siu, Wan-Chi},
  journal={Journal of Energy Storage},
  volume={53},
  pages={105149},
  year={2022},
  publisher={Elsevier},
  doi={10.1016/j.est.2022.105149}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{sadeghi2021deep,
  title={Cost and Power Loss Aware Coalitions under Uncertainty in Transactive Energy Systems},
  author={Sadeghi},
  journal={Universit√© d'Ottawa / University of Ottawa},
  year={2021}
}


@article{salvatti2020electric,
  author = {Salvatti, Gabriel Antonio and Carati, Emerson Giovani and Cardoso, Rafael and da Costa, Jean Patric and Stein, Carlos Marcelo de Oliveira},
  title = {Electric Vehicles Energy Management with V2G/G2V Multifactor Optimization of Smart Grids},
  journal = {Energies},
  volume = {13},
  number = {5},
  pages = {1191},
  year = {2020},
  publisher={MDPI},
  doi={10.3390/en13051191}
}

@article{zou2021deep,
  title={Deep reinforcement learning-based control strategies for electric vehicle charging and V2G services},
  author={Hongbin Xie},
  journal={Advances in Applied Energy},
  year={2021},
  doi={https://doi.org/10.1016/j.adapen.2025.100214}
}

@article{ghosh2024optimal,
  title={Optimal scheduling and control of V2G-enabled electric vehicles using advanced optimization and reinforcement learning techniques},
  author={Yuxin Wen},
  journal={sustainability},
  year={2022}
}
%%%%%%%%%%%%%%%%%%%%%%%
 %% A recent and comprehensive review on the evolution of smart grids and the application of RL,
  %% covering applications, challenges, and future research directions.
@article{alhmoud2024review,
 
  title={A Review of Smart Grid Evolution and Reinforcement Learning: Applications, Challenges and Future Directions},
  author={Al-HMOUD, Ghaith and Al-Raweshidy, Hamed},
  journal={Energies},
  volume={18},
  number={7},
  pages={1837},
  year={2024},
  publisher={MDPI},
  doi={10.3390/en18071837}
}
  %% This review focuses specifically on the applications and control strategies for bidirectional charging,
  %% which is central to the V2G concept explored in the thesis.
@article{khan2024review,

  title={A Review of Bidirectional Charging Grid Support Applications and Control},
  author={Khan, Sheroz Ullah and Mehmood, Khalid Kamran and Haider, Zia Muhammad and Bukhari, Syed Sabir Hussain and Lee, Sang-Jun and Rafique, Muhammad Kashif and Kim, Chul-Hwan},
  journal={Energies},
  volume={17},
  number={6},
  pages={1320},
  year={2024},
  publisher={MDPI},
  doi={10.3390/en17061320}
}
  %% A review focusing on the integration of EVs and renewable energy sources, highlighting the role of
  %% metaheuristic algorithms for energy management between V2G and G2V.
@article{kumar2024integration,

  title={Integration of electric vehicle into smart grid: a meta heuristic algorithm for energy management between V2G and G2V},
  author={Kumar, Vinay and Singh, Surender and Kumar, Dinesh},
  journal={Frontiers in Energy Research},
  volume={12},
  pages={1357863},
  year={2024},
  publisher={Frontiers Media SA},
  doi={10.3389/fenrg.2024.1357863}
}
  %% An early, influential work detailing the potential of V2G for providing key grid services
  %% like frequency regulation and peak shaving, establishing the economic and technical rationale.
@article{white2011vehicle,

  title={Vehicle-to-grid technology for frequency regulation and peak shaving},
  author={White, C. David and Zhang, Willett Kempton},
  journal={Journal of Power Sources},
  volume={196},
  number={3},
  pages={3972--3980},
  year={2011},
  publisher={Elsevier},
  doi={10.1016/j.jpowsour.2010.11.010}
}


%% =====================================================================
%% B. Core Methodologies: Reinforcement Learning in V2G
%% =====================================================================
%% This section contains papers that directly apply Deep Reinforcement Learning (DRL)
%% to the problem of EV charging and V2G management.


  %% A core paper for this thesis, proposing a DRL-based strategy for V2G services in a volatile
  %% market, directly aligning with the thesis's objective of handling economic uncertainty.
@article{orfanoudakis2022deep,

  title={A Deep Reinforcement Learning-Based Charging Strategy for Electric Vehicles with V2G Services in a Volatile Market},
  author={Orfanoudakis, Stylianos and Diaz-Londono, Christian and Yilmaz, Yasin Emir and Palensky, Peter and Vergara, Pedro P},
  journal={arXiv preprint arXiv:2209.09772},
  year={2022},
  doi={10.48550/arXiv.2209.09772}
}




  %% Focuses on a specific and critical V2G service: supplementary frequency regulation.
  %% This paper uses DRL to achieve optimal control for this task.
@article{alfaverh2022optima,

  title={Optimal vehicle-to-grid control for supplementary frequency regulation using deep reinforcement learning},
  author={Alfaverh, Farag and Dena{\"i}, Mouloud and Sun, Yifei},
  journal={Applied Energy},
  volume={325},
  pages={119881},
  year={2022},
  publisher={Elsevier},
  doi={10.1016/j.apenergy.2022.119881}
}


  %% Addresses the optimal scheduling problem for both charging and discharging using DRL,
  %% relevant for the multi-objective nature of the thesis.
@article{liu2023optimal,

  title={Optimal scheduling for charging and discharging of electric vehicles based on deep reinforcement learning},
  author={Liu, Zhaomiao and Wang, Jian and Zeng, Bo and Sun, Wei},
  journal={Frontiers in Energy Research},
  volume={11},
  pages={1273820},
  year={2023},
  publisher={Frontiers Media SA},
  doi={10.3389/fenrg.2023.1273820}
}


  %% This work applies DRL with a specific focus on a critical grid constraint: maintaining
  %% voltage stability in the distribution network during EV charging.
@article{wang2023deep,

  title={Deep reinforcement learning for charging scheduling of electric vehicles considering distribution network voltage stability},
  author={Wang, Sihan and Li, Jiaming and Wu, Lei and Li, Xiaopeng},
  journal={Sensors},
  volume={23},
  number={3},
  pages={1618},
  year={2023},
  publisher={MDPI},
  doi={10.3390/s23031618}
}


  %% A very recent paper on using RL for smart EV charging management, useful for showing
  %% the current state of research in 2024/2025.
@article{alogaili2024smart,

  title={Smart Electric Vehicle Charging Management Using Reinforcement Learning},
  author={Al-Ogaili, Ali S and Al-Shetwi, Ali Q and Al-Masri, Hadeel M and Al-Masri, Anas HM and Al-Zaidi, Raghad},
  journal={Sensors},
  volume={25},
  number={8},
  pages={2585},
  year={2024},
  publisher={MDPI},
  doi={10.3390/s25082585}
}


  %% Focuses on using Deep Q-Learning (DQN), a specific DRL algorithm, for demand response,
  %% which is a key V2G service.
@article{kumar2024deep,

  title={A Deep Q-Learning based Smart Scheduling of EVs for Demand Response},
  author={Kumar, Vikash and Pandey, Indra Kumar and Shukla, Ayush},
  journal={arXiv preprint arXiv:2401.02653},
  year={2024},
  doi={10.48550/arXiv.2401.02653}
}

  %% Another example of applying RL to demand response management assisted by EVs.

@article{wang2022electrical,

  title={An electrical vehicle-assisted demand response management system: A reinforcement learning method},
  author={Wang, Zhaoyu and Wang, Li and Wang, Siyuan and Zhang, Zhaoyang},
  journal={Frontiers in Energy Research},
  volume={10},
  pages={1071948},
  year={2022},
  publisher={Frontiers},
  doi={10.3389/fenrg.2022.1071948}
}

%% =====================================================================
%% C. Alternative Control Paradigms: Model Predictive Control (MPC)
%% =====================================================================
%% This section groups papers focused on MPC, the primary model-based benchmark against which
%% the DRL agents in this thesis are compared.



  %% A systematic review of MPC for V2G applications. Essential for establishing the state-of-the-art
  %% for the benchmark control strategy.
@article{minchala2025systematic,

  title={A Systematic Review of Model Predictive Control for Robust and Efficient Energy Management in Electric Vehicle Integration and V2G Applications},
  author={Minchala-\ \'Avila, Carlos A and Ar\ \'evalo, Pa\ \'ul and Ochoa-Correa, Diego},
  journal={Modelling},
  volume={6},
  number={1},
  pages={20},
  year={2025},
  publisher={MDPI},
  doi={10.3390/modelling6010020}
}



  %% A Master's thesis that provides a practical design and testing of both online (MPC) and offline
  %% optimization algorithms for V2G, relevant to the thesis's comparison methodology
@mastersthesis{faggio2023design,
  title={Design and Testing of Online and Offline Optimization Algorithms for Vehicle-to-Grid (V2G) Industrial Applications},
  author={Faggio, Gabriele},
  year={2023},
  school={Politecnico di Milano}
}


  %% Details a computationally efficient MPC implementation for residential V2G, which is a
  %% relevant use case and benchmark.
@article{schwenk2022computationally,

  title={A computationally efficient MPC for residential EV charging with V2G and 3-phase power flow},
  author={Schwenk, Johannes and Tuchschmid, Michael and Heer, Philipp and Elbert, Philipp},
  journal={Energies},
  volume={15},
  number={16},
  pages={5923},
  year={2022},
  publisher={MDPI},
  doi={10.3390/en15165923}
}

%% =====================================================================
%% D. Specific Technical Challenges & Models (Degradation, Simulation)
%% =====================================================================
%% This section contains papers that focus on specific, crucial components of the V2G problem,
%% such as battery degradation modeling, and the simulation frameworks used for research.



  %% A highly relevant paper that explicitly considers battery health within a safe RL framework,
  %% directly addressing one of the core multi-objective trade-offs of the thesis.
@article{gu2025optimization,

  title={Optimization of Electric Vehicle Charging and Discharging Strategies Considering Battery Health State: A Safe Reinforcement Learning Approach},
  author={Gu, Siyuan and Qian, Kun and Yang, Yang},
  journal={World Electric Vehicle Journal},
  volume={16},
  number={5},
  pages={286},
  year={2025},
  publisher={MDPI},
  doi={10.3390/wevj16050286}
}



 %% This work integrates battery degradation models into a DRL framework for V2G, providing a
  %% direct reference for the battery health preservation objective.

@article{shibl2023electric,
 
  title={Electric vehicles charging management using deep reinforcement learning considering vehicle-to-grid operation and battery degradation},
  author={Shibl, Mohamed M and Ismail, Loay S and Massoud, Ahmed M},
  journal={Energy Reports},
  volume={10},
  pages={494--509},
  year={2023},
  publisher={Elsevier},
  doi={10.1016/j.egyr.2023.07.039}
}

@article{birkl2017degradation,
  title={Degradation diagnostics for lithium ion cells},
  author={Birkl, Christoph R and Roberts, Malcolm R and McTurk, Edward and Bruce, Peter G and Howey, David A},
  journal={Journal of Power Sources},
  volume={341},
  pages={373--386},
  year={2017}
}

@article{vetter2005ageing,
  title={Ageing mechanisms in lithium-ion batteries},
  author={Vetter, Joachim and Nov\ \'ak, Pavel and Wagner, Michael R and Veit, Christoph and M\ \'oller, Kerstin C and Besenhard, J\ \'org O and Winter, Martin and Wohlfahrt-Mehrens, Margret and Vogler, Christian and Hammouche, Adnan},
  journal={Journal of Power Sources},
  volume={147},
  number={1--2},
  pages={269--281},
  year={2005}
}

  %% The foundational paper for the EV2Gym simulator, which is the core experimental platform
  %% enhanced and utilized in this thesis.
@article{orfanoudakis2024ev2gym,

  title={EV2Gym: A Flexible V2G Simulator for EV Smart Charging Research and Benchmarking},
  author={Orfanoudakis, Stylianos and Diaz-Londono, Christian and Y\ \"ilmaz, Yasin Emir and Palensky, Peter and Vergara, Pedro P},
  journal={arXiv preprint arXiv:2404.01849},
  year={2024},
  doi={10.48550/arXiv.2404.01849}
}
  %% The original paper for OpenAI Gym, the API standard upon which EV2Gym and many other
  %% RL research environments are built.
@article{brockman2016openai,

  title={OpenAI Gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016},
  doi={10.48550/arXiv.1606.01540}
}

%% =====================================================================
%% E. Foundational AI & Reinforcement Learning Theory
%% =====================================================================
%% This section includes seminal papers on the specific DRL algorithms and theoretical concepts
%% that are mentioned or used in the thesis.

  %% The original paper introducing the Deep Deterministic Policy Gradient (DDPG) algorithm,
  %% a foundational method for continuous control in DRL.
@article{lillicrap2015continuous,

  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

  %% Introduces the Twin Delayed DDPG (TD3) algorithm, which addresses key instabilities in DDPG
  %% and serves as a strong baseline for modern actor-critic methods.
@inproceedings{fujimoto2018addressing,

  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and van Hoof, Herke and Meger, David},
  booktitle={International conference on machine learning},
  pages={1587--1596},
  year={2018},
  organization={PMLR}
}

 %% The seminal paper on Soft Actor-Critic (SAC), a state-of-the-art algorithm based on the
  %% maximum entropy framework, known for its sample efficiency and stability.
@inproceedings{haarnoja2018soft,
 
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

  %% Introduces Prioritized Experience Replay (PER), a key technique for improving the sample
  %% efficiency of off-policy DRL algorithms like DQN.
@article{schaul2015prioritized,

  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015},
  doi={10.48550/arXiv.1511.05952}
}

  %% The foundational paper on Potential-Based Reward Shaping (PBRS), a theoretically sound method
  %% for accelerating RL without changing the optimal policy.
@article{ng1999policy,

  title={Policy invariance under reward transformations: Theory and application to reward shaping},
  author={Ng, Andrew Y and Harada, Daishi and Russell, Stuart},
  journal={ICML},
  volume={99},
  pages={278--287},
  year={1999}
}

  %% This paper is crucial for the thesis's exploration of advanced training techniques, as it
  %% specifically proposes a dynamic, adaptive reward function for V2G that considers battery degradation.
@article{wan2022dynamic,

  title={A dynamic reward-based deep reinforcement learning for V2G control with EV battery degradation},
  author={Wan, Zhong and Wang, Jian and Zhang, Weilin and Gu, Chen},
  journal={Applied Energy},
  volume={309},
  pages={118462},
  year={2022},
  publisher={Elsevier},
  doi={10.1016/j.apenergy.2021.118462}
}

%% =====================================================================
%% F. Policy, Regulation, and User-Centric Perspectives
%% =====================================================================
%% This section provides the broader context for the V2G problem, including European policy
documents and research focusing on the end-user's perspective.

  %% A key policy document from the European Commission that sets the ambitious climate targets
  %% driving the push for EVs and V2G technology.
@techreport{european_commission_2021_fit_for_55,
  title       = {'Fit for 55': delivering the EU's 2030 Climate Target on the way to climate neutrality},
  institution = {European Commission},
  year        = {2021},
  number      = {COM(2021) 550 final},
  address     = {Brussels}
}

  %% Provides a user-centric perspective on V2G, which is essential for understanding the
  %% user satisfaction constraints that any practical algorithm must respect.
@mastersthesis{evertsson2024investigating,

  title={Investigating Vehicle-to-grid from a User-centric Perspective},
  author={Evertsson, Albin and Nylander, Anton},
  year={2024},
  school={Chalmers University of Technology}
}
@article{wang2022multi,
  title={Multi-objective optimal scheduling of charging stations with solar-storage-diesel generator system},
  author={Wang, Siyuan and Wang, Shuo and Liu, Bo},
  journal={Frontiers in Energy Research},
  volume={10},
  pages={1042882},
  year={2022},
  publisher={Frontiers},
  doi={10.3389/fenrg.2022.1042882}
}
@article{logeshwaran2022comparative,
  title={A comparative study of deep reinforcement learning algorithms for energy management in commercial buildings},
  author={Logeshwaran, J and Fan, Chao and Naung, Swan Htet},
  journal={Energy and Buildings},
  volume={254},
  pages={111589},
  year={2022},
  publisher={Elsevier}
}
@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016},
  organization={PMLR}
}
@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015},
  organization={PMLR}
}
@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}
@inproceedings{mania2018simple,
  title={Simple random search of static linear policies is competitive for reinforcement learning},
  author={Mania, Horia and Guy, Aurelia and Recht, Benjamin},
  booktitle={Advances in neural information processing systems},
  volume={31},
  year={2018}
}
@inproceedings{kuznetsov2020controlling,
  title={Controlling overestimation bias with truncated quantile critics},
  author={Kuznetsov, Anton and Shvechikov, Pavel and Grishin, Alexander and Vetrov, Dmitry},
  booktitle={International Conference on Machine Learning},
  pages={5528--5538},
  year={2020},
  organization={PMLR}
}

@inproceedings{Cutler1980,
  author    = {Cutler, C. R. and Ramaker, B. L.},
  title     = {Dynamic Matrix Control - A Computer Control Algorithm},
  booktitle = {Proceedings of the 1980 Joint Automatic Control Conference},
  year      = {1980},
  publisher = {American Society of Mechanical Engineers (ASME)},
  address   = {San Francisco, CA},
  note      = {Paper No. WP5-B}
}

@article{Richalet1978ModelPH,
  title={Model predictive heuristic control: Applications to industrial processes},
  author={J. Richalet and A. Rault and J. L. Testud and J. Papon},
  journal={Automatica},
  year={1978},
  volume={14},
  pages={413-428}
}

@article{mayne2000constrained,
  title={Constrained model predictive control: Stability and optimality},
  author={Mayne, D. Q. and Rawlings, J. B. and Rao, C. V. and Scokaert, P. O. M.},
  journal={Automatica},
  volume={36},
  number={6},
  pages={789--814},
  year={2000},
  publisher={Elsevier}
}

@article{ibrahim2024comprehensive,
  title={Comprehensive Overview of Reward Engineering and Shaping in Advancing Reinforcement Learning Applications},
  author={Ibrahim, Sinan and Mostafa, Mostafa and Jnadi, Ali and Osinenko, Pavel},
  journal={arXiv preprint arXiv:2408.10215},
  year={2024}
}

@article{Tavakoli2019,
  author = {Tavakoli, Ahmad and Saha, Sajeeb and Arif, Mohammad Taufiqul and Haque, Md Enamul and Mendis, Nishad and Oo, Aman M.T.},
  title = {Impacts of grid integration of solar PV and electric vehicle on grid stability, power quality and energy economics: a review},
  journal = {IET Energy Systems Integration},
  volume = {2},
  number = {3},
  pages = {233--245},
  year = {2020},
  doi = {10.1049/iet-esi.2019.0047}
}
