\babel@toc {english}{}\relax 
\babel@toc {italian}{}\relax 
\babel@toc {english}{}\relax 
\contentsline {chapter}{List of Acronyms}{4}{section*.4}%
\contentsline {chapter}{\numberline {1}Introduction}{7}{chapter.1}%
\contentsline {subsection}{\numberline {1.0.1}Background and Relevance of Electric Vehicles and Vehicle-to-Grid}{7}{subsection.1.0.1}%
\contentsline {subsection}{\numberline {1.0.2}Challenges in EV Integration into the Electricity Grid and the Role of Artificial Intelligence}{8}{subsection.1.0.2}%
\contentsline {subsection}{\numberline {1.0.3}Objectives and Contributions of the Thesis}{9}{subsection.1.0.3}%
\contentsline {subsection}{\numberline {1.0.4}Research Methodology}{9}{subsection.1.0.4}%
\contentsline {subsection}{\numberline {1.0.5}Thesis Structure}{11}{subsection.1.0.5}%
\contentsline {chapter}{\numberline {2}State of the Art in Optimal V2G Management}{12}{chapter.2}%
\contentsline {section}{\numberline {2.1}The V2G Imperative: A Cornerstone of Europe's Green Transition}{12}{section.2.1}%
\contentsline {section}{\numberline {2.2}The Optimizer's Trilemma: Navigating a Stochastic World}{14}{section.2.2}%
\contentsline {section}{\numberline {2.3}The Economics of V2G: Navigating Energy Markets}{14}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Sources for Energy Price Data}{14}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}Buying vs. Selling: The Retail-Wholesale Spread}{15}{subsection.2.3.2}%
\contentsline {section}{\numberline {2.4}The Electric Vehicle and the V2G Scenario}{16}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Key Characteristics of a Grid-Interactive EV}{16}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}Deconstructing the V2G Scenario: A Conceptual Overview}{16}{subsection.2.4.2}%
\contentsline {section}{\numberline {2.5}A New Paradigm for Control: Reinforcement Learning}{17}{section.2.5}%
\contentsline {subsection}{\numberline {2.5.1}The Language of Learning: Markov Decision Processes (MDPs)}{18}{subsection.2.5.1}%
\contentsline {subsection}{\numberline {2.5.2}Judging the Future: Value Functions and Actor-Critic Architectures}{18}{subsection.2.5.2}%
\contentsline {section}{\numberline {2.6}Reward Engineering: Shaping Agent Behavior}{18}{section.2.6}%
\contentsline {subsection}{\numberline {2.6.1}Potential-Based Reward Shaping (PBRS)}{19}{subsection.2.6.1}%
\contentsline {subsection}{\numberline {2.6.2}Dynamic and Adaptive Rewards}{19}{subsection.2.6.2}%
\contentsline {subsection}{\numberline {2.6.3}Curriculum Learning}{19}{subsection.2.6.3}%
\contentsline {section}{\numberline {2.7}The Rise of Deep Reinforcement Learning for V2G Control}{20}{section.2.7}%
\contentsline {subsection}{\numberline {2.7.1}Off-Policy Methods: Data-Efficient Learning from Experience}{20}{subsection.2.7.1}%
\contentsline {paragraph}{Deep Deterministic Policy Gradient (DDPG)}{20}{section*.5}%
\contentsline {paragraph}{Twin Delayed DDPG (TD3)}{20}{section*.6}%
\contentsline {paragraph}{Soft Actor-Critic (SAC)}{21}{section*.7}%
\contentsline {paragraph}{Truncated Quantile Critics (TQC)}{21}{section*.8}%
\contentsline {paragraph}{Enhancement: Prioritized Experience Replay (PER)}{21}{section*.9}%
\contentsline {subsection}{\numberline {2.7.2}On-Policy Methods: Stability through Cautious Updates}{21}{subsection.2.7.2}%
\contentsline {paragraph}{Advantage Actor-Critic (A2C/A3C)}{21}{section*.10}%
\contentsline {paragraph}{Trust Region Policy Optimization (TRPO)}{22}{section*.11}%
\contentsline {paragraph}{Proximal Policy Optimization (PPO)}{22}{section*.12}%
\contentsline {subsection}{\numberline {2.7.3}Gradient-Free Methods: An Alternative Path}{22}{subsection.2.7.3}%
\contentsline {paragraph}{Augmented Random Search (ARS)}{22}{section*.13}%
\contentsline {section}{\numberline {2.8}The Model-Based Benchmark: Model Predictive Control (MPC)}{22}{section.2.8}%
\contentsline {subsection}{\numberline {2.8.1}Implicit MPC: Online Optimization}{23}{subsection.2.8.1}%
\contentsline {subsection}{\numberline {2.8.2}Explicit MPC: Offline Pre-computation}{23}{subsection.2.8.2}%
\contentsline {section}{\numberline {2.9}A Comparative Perspective on Control Methodologies}{24}{section.2.9}%
\contentsline {section}{\numberline {2.10}A Primer on Lithium-Ion Battery Chemistries and Degradation}{25}{section.2.10}%
\contentsline {subsection}{\numberline {2.10.1}Fundamental Concepts and Degradation Mechanisms}{26}{subsection.2.10.1}%
\contentsline {subsection}{\numberline {2.10.2}Key Automotive Chemistries}{27}{subsection.2.10.2}%
\contentsline {subsection}{\numberline {2.10.3}Voltage Profiles and the Challenge of SoC Estimation}{27}{subsection.2.10.3}%
\contentsline {subsection}{\numberline {2.10.4}Comparative Analysis and Safety Considerations}{28}{subsection.2.10.4}%
\contentsline {subsection}{\numberline {2.10.5}Battery Pack Architecture}{28}{subsection.2.10.5}%
\contentsline {chapter}{\numberline {3}An Enhanced V2G Simulation Framework for Robust Control}{30}{chapter.3}%
\contentsline {section}{\numberline {3.1}Core Simulator Architecture}{30}{section.3.1}%
\contentsline {section}{\numberline {3.2}Core Physical Models}{31}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}EV Model and Charging/Discharging Dynamics}{31}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}Battery Degradation Model}{31}{subsection.3.2.2}%
\contentsline {subsection}{\numberline {3.2.3}EV Behavior and Grid Models}{32}{subsection.3.2.3}%
\contentsline {section}{\numberline {3.3}A Unified Experimentation and Evaluation Workflow}{32}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Orchestration via \texttt {run\_experiments.py}}{32}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}Dual-Mode Training: Specialists and Generalists}{33}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}Reproducible Benchmarking and Evaluation}{33}{subsection.3.3.3}%
\contentsline {section}{\numberline {3.4}Evaluation Metrics}{33}{section.3.4}%
\contentsline {section}{\numberline {3.5}Simulator Implementation Details}{34}{section.3.5}%
\contentsline {subsubsection}{Vehicle Definition Modes}{34}{section*.14}%
\contentsline {subsubsection}{Empirical Calibration of the Degradation Model}{35}{section*.15}%
\contentsline {section}{\numberline {3.6}Reinforcement Learning Formulation}{35}{section.3.6}%
\contentsline {subsection}{\numberline {3.6.1}State Space ($S$)}{36}{subsection.3.6.1}%
\contentsline {subsection}{\numberline {3.6.2}Action Space ($A$)}{36}{subsection.3.6.2}%
\contentsline {subsection}{\numberline {3.6.3}Reward Function}{36}{subsection.3.6.3}%
\contentsline {section}{\numberline {3.7}Reinforcement Learning Algorithms}{37}{section.3.7}%
\contentsline {subsubsection}{Soft Actor-Critic (SAC)}{37}{section*.16}%
\contentsline {subsubsection}{Deep Deterministic Policy Gradient + PER (DDPG+PER)}{37}{section*.17}%
\contentsline {subsubsection}{Truncated Quantile Critics (TQC)}{38}{section*.18}%
\contentsline {subsection}{\numberline {3.7.1}A History-Based Adaptive Reward for Profit Maximization}{39}{subsection.3.7.1}%
\contentsline {subsubsection}{Economic Profit}{39}{section*.19}%
\contentsline {subsubsection}{Adaptive User Satisfaction Penalty}{39}{section*.20}%
\contentsline {subsubsection}{Adaptive Transformer Overload Penalty}{40}{section*.21}%
\contentsline {subsubsection}{Rationale and Significance}{40}{section*.22}%
\contentsline {section}{\numberline {3.8}Model Predictive Control (MPC)}{41}{section.3.8}%
\contentsline {subsection}{\numberline {3.8.1}System Model}{41}{subsection.3.8.1}%
\contentsline {subsection}{\numberline {3.8.2}Optimization Problem}{41}{subsection.3.8.2}%
\contentsline {section}{\numberline {3.9}Offline Optimization with Gurobi}{41}{section.3.9}%
\contentsline {subsection}{\numberline {3.9.1}Decision Variables}{41}{subsection.3.9.1}%
\contentsline {subsection}{\numberline {3.9.2}Objective Function (Example: Profit Maximization)}{42}{subsection.3.9.2}%
\contentsline {subsection}{\numberline {3.9.3}Main Constraints}{42}{subsection.3.9.3}%
\contentsline {section}{\numberline {3.10}Online MPC Formulation (PuLP Implementation)}{42}{section.3.10}%
\contentsline {subsection}{\numberline {3.10.1}Mathematical Formulation}{42}{subsection.3.10.1}%
\contentsline {subsubsection}{Objective Function: Net Operational Profit}{43}{section*.23}%
\contentsline {subsubsection}{System Constraints}{43}{section*.24}%
\contentsline {paragraph}{Energy Balance Dynamics.}{43}{section*.25}%
\contentsline {paragraph}{Power Limits and Mutual Exclusion.}{43}{section*.26}%
\contentsline {paragraph}{State of Energy (SoE) Limits.}{43}{section*.27}%
\contentsline {paragraph}{User Satisfaction (Hard Constraint).}{44}{section*.28}%
\contentsline {paragraph}{Transformer Power Limit.}{44}{section*.29}%
\contentsline {section}{\numberline {3.11}Conceptual Comparison: PuLP MPC vs. Gurobi Offline Optimizer}{44}{section.3.11}%
\contentsline {subsection}{\numberline {3.11.1}Core Philosophy: Controller vs. Judge}{44}{subsection.3.11.1}%
\contentsline {subsection}{\numberline {3.11.2}Objective Function: Operational Profit vs. Energy Arbitrage}{44}{subsection.3.11.2}%
\contentsline {subsection}{\numberline {3.11.3}Handling of User Satisfaction: Hard vs. Soft Constraints}{45}{subsection.3.11.3}%
